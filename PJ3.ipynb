{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P03 - Fake news detection",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Thư viện"
      ],
      "metadata": {
        "id": "00VFkB1qfUPv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i7e85P-iOiOC"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pyvi: https://pypi.org/project/pyvi/0.0.7.5/ - Vietnamese tokenizing tool\n",
        "# !pip install pyvi\n",
        "from pyvi import ViTokenizer, ViPosTagger"
      ],
      "metadata": {
        "id": "OKIC69ERKJXS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dữ liệu\n",
        "\n",
        "Nguồn dữ liệu: VNFD Dataset - [vn_news_223_tdlfr.csv](https://github.com/thanhhocse96/vfnd-vietnamese-fake-news-datasets/blob/master/CSV/vn_news_223_tdlfr.csv)\n",
        "\n",
        "Mô tả dữ liệu: [Mô tả tập VNFD](https://github.com/thanhhocse96/vfnd-vietnamese-fake-news-datasets/tree/master/CSV)"
      ],
      "metadata": {
        "id": "lC3jSCDpeKid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data/vn_news_223_tdlfr.csv\")\n",
        "df = df.drop(columns=['domain'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "Qsc_NwtYPRMd",
        "outputId": "243ec927-c4f6-4e91-dbf6-f6579af94a18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-677f2c2f-73a4-44fc-aafb-ad181709faee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thủ tướng Nhật cúi đầu xin lỗi vì tinh thần ph...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Choáng! Cơ trưởng đeo khăn quàng quẩy banh nóc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chưa bao giờ nhạc Kpop lại dễ hát đến thế!!!\\n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Đại học Hutech sẽ áp dụng cải cách \"Tiếq Việt\"...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>“Siêu máy bay” A350 sẽ chở CĐV Việt Nam đi Mal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>Thưởng 20.000 USD cho đội tuyển cờ vua Việt Na...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>Trường Sơn giành HCV tại giải cờ vua đồng đội ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>Chuyện về chàng sinh viên Luật - Kiện tướng Lê...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>Tiền đạo Malaysia: “Tôi đã có cách vượt qua hà...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>223 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-677f2c2f-73a4-44fc-aafb-ad181709faee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-677f2c2f-73a4-44fc-aafb-ad181709faee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-677f2c2f-73a4-44fc-aafb-ad181709faee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  text  label\n",
              "0    Thủ tướng Abe cúi đầu xin lỗi vì hành động phi...      1\n",
              "1    Thủ tướng Nhật cúi đầu xin lỗi vì tinh thần ph...      1\n",
              "2    Choáng! Cơ trưởng đeo khăn quàng quẩy banh nóc...      1\n",
              "3    Chưa bao giờ nhạc Kpop lại dễ hát đến thế!!!\\n...      1\n",
              "4    Đại học Hutech sẽ áp dụng cải cách \"Tiếq Việt\"...      1\n",
              "..                                                 ...    ...\n",
              "218  “Siêu máy bay” A350 sẽ chở CĐV Việt Nam đi Mal...      0\n",
              "219  Thưởng 20.000 USD cho đội tuyển cờ vua Việt Na...      0\n",
              "220  Trường Sơn giành HCV tại giải cờ vua đồng đội ...      0\n",
              "221  Chuyện về chàng sinh viên Luật - Kiện tướng Lê...      0\n",
              "222  Tiền đạo Malaysia: “Tôi đã có cách vượt qua hà...      0\n",
              "\n",
              "[223 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chúng ta sẽ chia dữ liệu thành 2 tập train và validation, với tỉ lệ 80/20.\n",
        "\n",
        "Từ giờ, mọi bước liên quan đến tiền xử lý, trích xuất đặc trưng, train mô hình học máy đều chỉ thực hiện trên tập train. Tập validation sẽ được để dành cho việc kiểm tra lại mô hình."
      ],
      "metadata": {
        "id": "ygwRbJJpL4_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_df = df.drop(\"label\", axis=1)\n",
        "Y_sr = df[\"label\"]\n",
        "\n",
        "train_X_df, val_X_df, train_Y_sr, val_Y_sr = train_test_split(\n",
        "    X_df, Y_sr, \n",
        "    test_size = 0.2, \n",
        "    stratify = Y_sr, \n",
        "    # random_state = 0\n",
        ")"
      ],
      "metadata": {
        "id": "Z2FN3voKiAWV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tiền xử lý văn bản tiếng Việt"
      ],
      "metadata": {
        "id": "ZRwuSPyFeEwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopwords: https://github.com/stopwords/vietnamese-stopwords/blob/master/vietnamese-stopwords.txt\n",
        "\n",
        "Tokenizer: Pyvi - Vietnamese tokenizing tool - https://pypi.org/project/pyvi/0.0.7.5/\n",
        "\n",
        "\n",
        "Quá trình xử lý 1 đoạn text được thực hiện như sau:\n",
        "\n",
        "* Tokenize\n",
        "* Remove punctuations\n",
        "* Remove special chars\n",
        "* Remove links\n",
        "* Lowercase\n",
        "* Remove stopwords"
      ],
      "metadata": {
        "id": "2ymy-5OJMkST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"stopwords/vietnamese-stopwords.txt\") as file:\n",
        "    stopwords = file.readlines()\n",
        "    stopwords = [word.rstrip() for word in stopwords]\n",
        "\n",
        "punctuations = '''!()-–=[]{}“”‘’;:'\"|\\,<>./?@#$%^&*_~'''\n",
        "\n",
        "special_chars = ['\\n', '\\t']\n",
        "\n",
        "regex = re.compile(\n",
        "        r'^(?:http|ftp)s?://' # http:// or https://\n",
        "        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|' # domain\n",
        "        r'localhost|' # localhost\n",
        "        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})' # ip\n",
        "        r'(?::\\d+)?' # port\n",
        "        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)   "
      ],
      "metadata": {
        "id": "Rgljv-JBPBnw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    tokenized_text = ViPosTagger.postagging(ViTokenizer.tokenize(text))\n",
        "    return tokenized_text[0]\n",
        "\n",
        "def is_punctuation(token):\n",
        "    global punctuations\n",
        "    return True if token in punctuations else False\n",
        "\n",
        "def is_special_chars(token):\n",
        "    global special_chars\n",
        "    return True if token in special_chars else False\n",
        "\n",
        "def is_link(token):\n",
        "    return re.match(regex, token) is not None\n",
        "\n",
        "def lowercase(token):\n",
        "    return token.lower()\n",
        "\n",
        "def is_stopword(token):\n",
        "    global stopwords\n",
        "    return True if token in stopwords else False\n",
        "\n",
        "# ===============================================================\n",
        "# Process:\n",
        "# Text -> Tokenize (pyvi) -> Remove punctuations -> Remove special chars \n",
        "# -> Remove links -> Lowercase -> Remove stopwords -> Final Tokens\n",
        "# ===============================================================\n",
        "def vietnamese_text_preprocessing(text):\n",
        "    tokens = tokenize(text)\n",
        "    tokens = [token for token in tokens if not is_punctuation(token)]\n",
        "    tokens = [token for token in tokens if not is_special_chars(token)]\n",
        "    tokens = [token for token in tokens if not is_link(token)]\n",
        "    tokens = [lowercase(token) for token in tokens]\n",
        "    tokens = [token for token in tokens if not is_stopword(token)]\n",
        "    # return tokens\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "FpfY8ebTKTrj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ví dụ sử dụng:"
      ],
      "metadata": {
        "id": "KGaMSfa5N1FU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trích 1 đoạn từ https://www.fit.hcmus.edu.vn/\n",
        "demo_text = 'Trải qua hơn 25 năm hoạt động, Khoa Công nghệ Thông tin (CNTT) đã phát triển vững chắc và được Chính phủ bảo trợ để trở thành một trong những khoa CNTT đầu ngành trong hệ thống giáo dục đại học của Việt Nam.'\n",
        "\n",
        "demo_text_to_tokens = vietnamese_text_preprocessing(demo_text)\n",
        "print(demo_text_to_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khKIj6EIN0Ux",
        "outputId": "292fb1e4-cf50-4a38-c16f-05b46833eaee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['trải', '25', 'hoạt_động', 'khoa', 'công_nghệ', 'thông_tin', 'cntt', 'phát_triển', 'vững_chắc', 'chính_phủ', 'bảo_trợ', 'trở_thành', 'khoa', 'cntt', 'đầu', 'ngành', 'hệ_thống', 'giáo_dục', 'đại_học', 'việt_nam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Xây dựng mô hình máy học: MLPClassifier"
      ],
      "metadata": {
        "id": "vAXiICVfFl5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Xây dựng pipeline\n",
        "\n",
        "Pipeline: \n",
        "* **PreprocessAndFeaturesExtract**: Tiền xử lý văn bản và trích xuất đặc trưng\n",
        "  * **Tiền xử lý văn bản**: Đã được cài đặt ở phần trên (hàm `vietnamese_text_preprocessing`)\n",
        "  * **Trích xuất đặc trưng**: Văn bản -> Ma trận đặc trưng TF-IDF (`sklearn.feature_extraction.text.TfidfVectorizer` - https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
        "* **Mô hình phân lớp mạng neural MLPClassifier** (`sklearn.neural_network.MLPClassifier` - https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)"
      ],
      "metadata": {
        "id": "UK_Snuj7G5DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PreprocessAndFeaturesExtract(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        # print(\"> PreprocessAndFeaturesExtract > INIT\")\n",
        "        self.trained_tokens = []\n",
        "\n",
        "    # ===============================================================\n",
        "    # Mỗi lần train chỉ gọi 1 lần fit\n",
        "    # Mỗi lần fit thì sẽ tạo 1 list trained_tokens, bao gồm những tokens/đặc trưng đã được train\n",
        "    # ===============================================================\n",
        "    def fit(self, X_df, y=None):\n",
        "\n",
        "        # Return a list of preprocessed_texts\n",
        "        preprocessed_texts = []\n",
        "        for index, row in X_df.iterrows():\n",
        "            tokens = vietnamese_text_preprocessing(row['text'])\n",
        "            preprocessed_texts.append(' '.join(tokens))\n",
        "        preprocessed_texts = np.array(preprocessed_texts)\n",
        "\n",
        "        # preprocessed_texts -> features\n",
        "        tv = TfidfVectorizer(min_df = 0.0, max_df = 1.0, use_idf = True)\n",
        "        tv_matrix = tv.fit_transform(preprocessed_texts)\n",
        "        tv_matrix = tv_matrix.toarray()\n",
        "        df_features = pd.DataFrame(np.round(tv_matrix, 2), columns = tv.get_feature_names_out())\n",
        "\n",
        "        self.trained_tokens = df_features.columns.values\n",
        "\n",
        "        # print(f\"> PreprocessAndFeaturesExtract > FIT > X_df: {X_df.shape} > df_features: {df_features.shape}\")\n",
        "        # print(f\"self.trained_tokens: {self.trained_tokens}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    # ===============================================================\n",
        "    # Khá giống phương thức fit (ở bước tiền xử lý, và trích xuất đặc trưng), tuy nhiên:\n",
        "    # fit:       Gọi 1 lần duy nhất mỗi lần train\n",
        "    # transform: Được gọi nhiều lần, và có thể áp dụng với nhiều X_df khác nhau (để tính score hay predict chẳng hạn),\n",
        "    #            dựa trên cái model đã được train trước đó bằng fit\n",
        "    # ===============================================================\n",
        "    # fit tạo mới self.trained_tokens, transform thì không\n",
        "    # ===============================================================\n",
        "    # transform được cài đặt để trả về những đặc trưng ĐÃ được học,\n",
        "    # những đặc trưng chưa học thì sẽ bỏ qua\n",
        "    # ===============================================================\n",
        "    def transform(self, X_df, y=None):\n",
        "\n",
        "        # Return a list of preprocessed_texts\n",
        "        preprocessed_texts = []\n",
        "        for index, row in X_df.iterrows():\n",
        "            tokens = vietnamese_text_preprocessing(row['text'])\n",
        "            preprocessed_texts.append(' '.join(tokens))\n",
        "        preprocessed_texts = np.array(preprocessed_texts)\n",
        "\n",
        "        # Features Extraction\n",
        "        # preprocessed_texts -> features\n",
        "        # TF-IDF Model\n",
        "        tv = TfidfVectorizer(min_df = 0.0, max_df = 1.0, use_idf = True)\n",
        "        tv_matrix = tv.fit_transform(preprocessed_texts)\n",
        "        tv_matrix = tv_matrix.toarray()\n",
        "        vocab = tv.get_feature_names_out()\n",
        "        temp_df_features = pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)\n",
        "\n",
        "        df_features = pd.DataFrame()\n",
        "\n",
        "        for trained_token in self.trained_tokens:\n",
        "            if trained_token in vocab:\n",
        "                df_features[trained_token] = temp_df_features[trained_token]\n",
        "            else:\n",
        "                df_features[trained_token] = 0.000\n",
        "\n",
        "        # print(f\"\\n> PreprocessAndFeaturesExtract > TRANSFORM > X_df: {X_df.shape} > df_features: {df_features.shape}\")\n",
        "\n",
        "        return df_features"
      ],
      "metadata": {
        "id": "EVnVUazCOPXM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLPClassifier\n",
        "mlp_classifier = MLPClassifier(\n",
        "    hidden_layer_sizes=(50),\n",
        "    activation='relu',\n",
        "    solver='lbfgs',\n",
        "    random_state=0,\n",
        "    max_iter=10000\n",
        ")\n",
        "\n",
        "# Pipeline: PreprocessAndFeaturesExtract -> MLPClassifier\n",
        "pipeline_mlp = Pipeline(\n",
        "    steps=[\n",
        "           (\"vnpreprocess\", PreprocessAndFeaturesExtract()),\n",
        "           (\"mlpclassifier\", mlp_classifier)\n",
        "           ]\n",
        ")\n",
        "pipeline_mlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "UygWu9YGZBcY",
        "outputId": "e3fb94bf-fcc1-4237-aed2-93204530fd21"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style>#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 {color: black;background-color: white;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 pre{padding: 0;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-toggleable {background-color: white;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-estimator:hover {background-color: #d4ebff;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-item {z-index: 1;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-parallel-item:only-child::after {width: 0;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77 div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-89ad51c8-d3ac-4577-96b6-32fb5f905c77\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"1c92feb7-8ed1-45f1-8f20-6b51e3fc3382\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"1c92feb7-8ed1-45f1-8f20-6b51e3fc3382\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('vnpreprocess', PreprocessAndFeaturesExtract()),\n",
              "                ('mlpclassifier',\n",
              "                 MLPClassifier(hidden_layer_sizes=50, max_iter=10000,\n",
              "                               random_state=0, solver='lbfgs'))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4e71472d-581b-409d-bc88-53bbfc3837cc\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"4e71472d-581b-409d-bc88-53bbfc3837cc\">PreprocessAndFeaturesExtract</label><div class=\"sk-toggleable__content\"><pre>PreprocessAndFeaturesExtract()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"07031f4a-c226-41cc-bd57-d5a57fd89817\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"07031f4a-c226-41cc-bd57-d5a57fd89817\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=50, max_iter=10000, random_state=0,\n",
              "              solver='lbfgs')</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('vnpreprocess', PreprocessAndFeaturesExtract()),\n",
              "                ('mlpclassifier',\n",
              "                 MLPClassifier(hidden_layer_sizes=50, max_iter=10000,\n",
              "                               random_state=0, solver='lbfgs'))])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train\n",
        "\n",
        "Tiến hành huấn luyện mô hình trên tập train"
      ],
      "metadata": {
        "id": "K-Dxt3MVQ5aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_mlp.fit(train_X_df, train_Y_sr)\n",
        "print(\"> Train completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0no_DNhzbsqR",
        "outputId": "0b750bc0-bb3b-4507-fdf3-77671b5e9fd7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Train completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Score\n",
        "\n",
        "Tính accuracy của mô hình, sử dụng lần lượt tập train và tập validation."
      ],
      "metadata": {
        "id": "nRnlrIqARBI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = pipeline_mlp.score(train_X_df, train_Y_sr)\n",
        "print(f\"Train Accuracy = {train_acc}\")\n",
        "\n",
        "val_acc = pipeline_mlp.score(val_X_df, val_Y_sr)\n",
        "print(f\"Validation Accuracy = {val_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpqE_JWqRDp8",
        "outputId": "a2b06415-c442-4c97-8094-37e809bd8822"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy = 1.0\n",
            "Validation Accuracy = 0.8888888888888888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predict\n",
        "\n",
        "Dự đoán label của văn bản mới"
      ],
      "metadata": {
        "id": "U_6Gyu2gSTBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Nếu có 1 tập muốn predict, tên \"predict_X_df\", thì predict tập đó như sau:\n",
        "# pred_results = pipeline_mlp.predict(predict_X_df)\n",
        "# pred_results"
      ],
      "metadata": {
        "id": "BLWAFrowSWO1"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}